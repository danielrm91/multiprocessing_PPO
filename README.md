# multiprocessing_PPO
In this repository, I set a PPO algorithm with multiprocessing for gathering experiences from the environment
